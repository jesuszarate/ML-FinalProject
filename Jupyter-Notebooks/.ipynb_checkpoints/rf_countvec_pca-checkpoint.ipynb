{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as  np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "path = os.path.abspath(os.getcwd()) + '/../data_load'\n",
    "sys.path.insert(0, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "\n",
    "def dateToInt(x):    \n",
    "    _date = x.split('/')\n",
    "    \n",
    "    year, time = _date[2].split()\n",
    "    hour, minute = time.split(':')\n",
    "\n",
    "    if int(hour) > 23:\n",
    "        hour = 23\n",
    "    if int(hour) < 0:\n",
    "        hour = 0\n",
    "        \n",
    "    t = datetime.datetime(int(year), int(_date[0]), int(_date[1]), int(hour), int(minute), 0, 0).timestamp()\n",
    "    return t\n",
    "\n",
    "def getLabelMap(data):\n",
    "    # Map shape to an integer\n",
    "    labels = data['shape']\n",
    "    labels = labels.unique()\n",
    "    nums = [i for i in range(len(labels))]\n",
    "    return dict(zip(labels, nums))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def vectorize(text):    \n",
    "    # create the transform\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    # tokenize and build vocab\n",
    "    vectorizer.fit(text)\n",
    "\n",
    "    # encode document\n",
    "    vector = vectorizer.transform(text)\n",
    "\n",
    "    return vector.toarray()\n",
    "\n",
    "def vectorize_dm(text):\n",
    "    n_features = 5000\n",
    "    n_top_words = 20\n",
    "\n",
    "    count_vectorizor = CountVectorizer(\n",
    "            max_df=0.95, \n",
    "            min_df=2,\n",
    "            max_features=n_features,\n",
    "            stop_words='english'\n",
    "    )\n",
    "    count = count_vectorizor.fit_transform(text)\n",
    "#     count_feature_names = count_vectorizor.get_feature_names()\n",
    "#     print(count_feature_names)\n",
    "    return count.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64896, 5000)\n",
      "(64896, 6)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "path = os.path.abspath(os.getcwd()) + '/../data_load'\n",
    "sys.path.insert(0, path)\n",
    "from ufo_data import UFOData\n",
    "\n",
    "names=['datetime', 'shape', 'duration(seconds)', 'comments','longitude', 'latitude']\n",
    "\n",
    "ufo_data = UFOData(cols=names, country='us')\n",
    "data = ufo_data.encoded()\n",
    "\n",
    "# Create dataframe out of the comment vector\n",
    "commentDf = pd.DataFrame(vectorize_dm(data['comments']))\n",
    "# commentDf['key'] = [i for i in range(commentDf.shape[0])]\n",
    "print(commentDf.shape)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Principle Component Anaysis (PCA) to only extract the 100 most relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=20)\n",
    "# XX = pca.fit_transform(X)\n",
    "\n",
    "commentDf = pca.fit_transform(commentDf)\n",
    "commentDf = pd.DataFrame(commentDf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the comment vectors with data\n",
    "#### Takes a  long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration(seconds)</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>key</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-638224200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2700</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.9411111</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.593106</td>\n",
       "      <td>-0.190754</td>\n",
       "      <td>-0.282319</td>\n",
       "      <td>-0.246346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013423</td>\n",
       "      <td>0.033908</td>\n",
       "      <td>-0.069386</td>\n",
       "      <td>-0.149881</td>\n",
       "      <td>-0.020947</td>\n",
       "      <td>-0.052927</td>\n",
       "      <td>-0.057061</td>\n",
       "      <td>-0.090469</td>\n",
       "      <td>0.077676</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-417297600.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.6458333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.409239</td>\n",
       "      <td>-0.201193</td>\n",
       "      <td>-0.328217</td>\n",
       "      <td>-0.263123</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029256</td>\n",
       "      <td>-0.009834</td>\n",
       "      <td>-0.110902</td>\n",
       "      <td>-0.138132</td>\n",
       "      <td>-0.010222</td>\n",
       "      <td>-0.090148</td>\n",
       "      <td>-0.061064</td>\n",
       "      <td>-0.063493</td>\n",
       "      <td>0.071035</td>\n",
       "      <td>-0.001467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-291070800.0</td>\n",
       "      <td>2</td>\n",
       "      <td>900</td>\n",
       "      <td>21.4180556</td>\n",
       "      <td>-157.8036111</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471579</td>\n",
       "      <td>-0.226775</td>\n",
       "      <td>-0.324663</td>\n",
       "      <td>-0.179354</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199356</td>\n",
       "      <td>-0.038473</td>\n",
       "      <td>0.074363</td>\n",
       "      <td>-0.133131</td>\n",
       "      <td>-0.006548</td>\n",
       "      <td>-0.177145</td>\n",
       "      <td>0.681737</td>\n",
       "      <td>-0.182291</td>\n",
       "      <td>-0.275436</td>\n",
       "      <td>-0.470383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-259538400.0</td>\n",
       "      <td>3</td>\n",
       "      <td>300</td>\n",
       "      <td>36.5950000</td>\n",
       "      <td>-82.1888889</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.594173</td>\n",
       "      <td>-0.198979</td>\n",
       "      <td>-0.289475</td>\n",
       "      <td>-0.260950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011656</td>\n",
       "      <td>0.040211</td>\n",
       "      <td>-0.067300</td>\n",
       "      <td>-0.166482</td>\n",
       "      <td>-0.030036</td>\n",
       "      <td>-0.069726</td>\n",
       "      <td>-0.097674</td>\n",
       "      <td>-0.081250</td>\n",
       "      <td>0.007450</td>\n",
       "      <td>-0.005534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-133294500.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1200</td>\n",
       "      <td>41.1175000</td>\n",
       "      <td>-73.4083333</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.542606</td>\n",
       "      <td>0.145994</td>\n",
       "      <td>0.040091</td>\n",
       "      <td>-0.161469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.193603</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.212747</td>\n",
       "      <td>0.180372</td>\n",
       "      <td>0.144095</td>\n",
       "      <td>0.029959</td>\n",
       "      <td>-0.222881</td>\n",
       "      <td>-0.117943</td>\n",
       "      <td>0.119518</td>\n",
       "      <td>-0.100727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      datetime  shape duration(seconds)   longitude      latitude  key  \\\n",
       "0 -638224200.0      0              2700  29.8830556   -97.9411111    0   \n",
       "1 -417297600.0      1                20  28.9783333   -96.6458333    1   \n",
       "2 -291070800.0      2               900  21.4180556  -157.8036111    2   \n",
       "3 -259538400.0      3               300  36.5950000   -82.1888889    3   \n",
       "4 -133294500.0      4              1200  41.1175000   -73.4083333    4   \n",
       "\n",
       "          0         1         2         3    ...           10        11  \\\n",
       "0 -0.593106 -0.190754 -0.282319 -0.246346    ...    -0.013423  0.033908   \n",
       "1  0.409239 -0.201193 -0.328217 -0.263123    ...    -0.029256 -0.009834   \n",
       "2  0.471579 -0.226775 -0.324663 -0.179354    ...    -0.199356 -0.038473   \n",
       "3 -0.594173 -0.198979 -0.289475 -0.260950    ...    -0.011656  0.040211   \n",
       "4 -0.542606  0.145994  0.040091 -0.161469    ...     0.193603  0.064815   \n",
       "\n",
       "         12        13        14        15        16        17        18  \\\n",
       "0 -0.069386 -0.149881 -0.020947 -0.052927 -0.057061 -0.090469  0.077676   \n",
       "1 -0.110902 -0.138132 -0.010222 -0.090148 -0.061064 -0.063493  0.071035   \n",
       "2  0.074363 -0.133131 -0.006548 -0.177145  0.681737 -0.182291 -0.275436   \n",
       "3 -0.067300 -0.166482 -0.030036 -0.069726 -0.097674 -0.081250  0.007450   \n",
       "4  0.212747  0.180372  0.144095  0.029959 -0.222881 -0.117943  0.119518   \n",
       "\n",
       "         19  \n",
       "0  0.000862  \n",
       "1 -0.001467  \n",
       "2 -0.470383  \n",
       "3 -0.005534  \n",
       "4 -0.100727  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Since we already vectorized the comments we can get rid of them now\n",
    "if 'comments' in names:\n",
    "    names.remove('comments')\n",
    "# names.remove('key')\n",
    "# Add key to merge the dataframes    \n",
    "if 'key' not in names:\n",
    "    names.append('key')\n",
    "    data['key'] = [i for i in range(data.shape[0])]\n",
    "    commentDf['key'] = [i for i in range(commentDf.shape[0])]        \n",
    "\n",
    "dt = data[names].merge(commentDf, on='key', how='left')\n",
    "\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_dict = getLabelMap(dt)\n",
    "\n",
    "Y = np.array(dt['shape']) #np.array([label_dict[i] for i in dt['shape']])\n",
    "\n",
    "x_cols = list(dt)\n",
    "\n",
    "if 'shape' in x_cols:\n",
    "    x_cols.remove('shape')\n",
    "\n",
    "X = dt[x_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.2, \n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=25, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# rf = RandomForestClassifier(n_estimators=25)\n",
    "rf = RandomForestClassifier(n_estimators=25, max_features='auto', max_depth=None)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31155624037\n",
      "4044\n"
     ]
    }
   ],
   "source": [
    "# pred = rf.predict(X_test)\n",
    "y_pred_probs = rf.predict_proba(X_test)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(rf.score(X_test, y_test))\n",
    "s = y_test\n",
    "count = 0\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == s[i]:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def RandomForest(X_train, y_train, X_test, y_test):\n",
    "    rf = RandomForestClassifier(n_estimators=25, max_features='auto', max_depth=None)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_probs = rf.predict_proba(X_test)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    print(rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy and F Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3115562403697997"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scores = f1_score(y_test, y_guess, average=None)\n",
    "scores = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.271473105065\n",
      "0.271473105065\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3115562403697997\n",
      "0.271473105065\n",
      "0.271473105065\n"
     ]
    }
   ],
   "source": [
    "print(count/len(y_pred))\n",
    "\n",
    "scores = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n",
    "\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   3,   22,   49,   18,   26,   23,   10,    5,   12,    1,    0,\n",
       "           0,   36,    1,    0,    1,    0,    0,    0,    1,    0,    0],\n",
       "       [   3,  166,  542,   74,   73,  144,   73,   18,   56,    0,    0,\n",
       "          14,  115,    3,    0,   11,    1,    3,    0,    0,    1,    0],\n",
       "       [   5,  203, 1750,   90,   72,  140,  136,   31,   62,    5,    2,\n",
       "          12,  174,    6,    0,   11,    1,    2,    1,    2,    0,    0],\n",
       "       [   7,  109,  302,   62,   64,  128,   48,   14,   36,    1,    0,\n",
       "           4,   59,    6,    0,    9,    1,    1,    2,    0,    0,    0],\n",
       "       [   3,   93,  175,   45,  178,   46,   52,   24,   42,    2,    1,\n",
       "           7,  127,    7,    0,    6,    1,    1,    2,    1,    0,    0],\n",
       "       [   6,  115,  286,   86,   40,  287,   39,   10,   29,    1,    1,\n",
       "           2,   55,    0,    0,    1,    0,    2,    4,    0,    0,    0],\n",
       "       [   2,   96,  467,   60,   72,   96,  204,   14,   43,    0,    1,\n",
       "           9,  134,    6,    0,    8,    1,    1,    0,    3,    0,    0],\n",
       "       [   7,   66,  175,   36,   65,   50,   42,   20,   27,    0,    0,\n",
       "           2,   92,    3,    0,    1,    0,    1,    0,    0,    0,    0],\n",
       "       [  10,   83,  289,   41,   74,   78,   65,   13,   52,    2,    1,\n",
       "           7,  144,    6,    0,    4,    2,    2,    1,    1,    0,    0],\n",
       "       [   0,   31,   73,   18,   20,   15,   16,    7,    8,    2,    1,\n",
       "           0,   43,    3,    0,    5,    0,    0,    0,    0,    0,    0],\n",
       "       [   2,   17,   43,    5,   12,   12,   14,    7,   11,    0,    2,\n",
       "           0,   43,    1,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   1,   43,  151,   16,   21,   29,   20,    7,   19,    1,    1,\n",
       "           9,   72,    2,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   5,  126,  337,   52,   90,   60,   96,   18,   60,    2,    6,\n",
       "          14,  414,    3,    0,    4,    2,    0,    1,    1,    1,    0],\n",
       "       [   1,   41,   88,   12,   44,   20,   31,    6,   20,    2,    0,\n",
       "           1,   55,    3,    0,    3,    0,    1,    0,    0,    0,    0],\n",
       "       [   0,    0,    1,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    1,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   1,   36,  130,   12,   24,   20,   31,    2,   17,    0,    0,\n",
       "           1,   49,    3,    0,    3,    1,    1,    0,    0,    0,    0],\n",
       "       [   0,   24,   68,   12,   10,   14,   12,    2,   10,    0,    0,\n",
       "           1,   34,    0,    0,    1,    0,    1,    0,    0,    0,    0],\n",
       "       [   0,   16,  104,    7,    7,   33,   10,    3,    6,    0,    0,\n",
       "           0,   10,    0,    0,    1,    0,    6,    0,    0,    0,    0],\n",
       "       [   0,    9,   35,    8,    5,   10,    7,    3,   13,    0,    0,\n",
       "           0,   11,    2,    0,    1,    0,    0,    0,    1,    0,    0],\n",
       "       [   0,   16,   43,   13,    5,    7,    8,    4,    4,    0,    0,\n",
       "           2,   22,    0,    0,    1,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    2,   17,    4,    3,    6,    4,    1,    3,    1,    0,\n",
       "           0,    5,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   1,    1,   12,    2,    0,    4,    2,    2,    2,    0,    0,\n",
       "           0,    9,    1,    0,    0,    0,    0,    0,    0,    0,    1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "def prepare_data(X, Y):\n",
    "\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        Y,\n",
    "        test_size=0.2, \n",
    "        random_state=42)\n",
    "    \n",
    "    scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "    X_train = scaling.transform(X_train)\n",
    "    X_test = scaling.transform(X_test)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training a linear SVM classifier\n",
    "from sklearn.svm import SVC\n",
    "def svm(X_train, y_train, X_test, y_test):\n",
    "   \n",
    "    svm_model_linear = SVC(kernel = 'linear', C = 1, cache_size=7000).fit(X_train, y_train)\n",
    "    svm_predictions = svm_model_linear.predict(X_test)\n",
    "\n",
    "    # model accuracy for X_test\n",
    "    accuracy = svm_model_linear.score(X_test, y_test)\n",
    "\n",
    "    # creating a confusion matrix\n",
    "#     cm = confusion_matrix(y_test, svm_predictions)\n",
    "    print(accuracy)\n",
    "#     return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# clusters: 2452\n",
      "Getting cluster sizes\n",
      "\n",
      "\n",
      "*** CLUSTER STATS ***\n",
      "\n",
      "Max Cluster Size = 17159\n",
      "Min Cluster Size = 3\n",
      "Avg. Size = 19.483265306122448\n",
      "Sanity Check Passed\n",
      "Scoring all data\n",
      "Filtering scores\n",
      "SVM\n",
      "0.211373504183\n",
      "Random Forest\n",
      "0.17123795404\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-7584f7d0b91c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Random Forest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mRandomForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-5f8399b93fb6>\u001b[0m in \u001b[0;36mRandomForest\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2476\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 2477\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   2478\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas/_libs/index.c:4404)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas/_libs/index.c:4087)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas/_libs/hashtable.c:14031)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas/_libs/hashtable.c:13975)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "path = os.path.abspath(os.getcwd()) + '/../credibility_score'\n",
    "sys.path.insert(0, path)\n",
    "\n",
    "path = os.path.abspath(os.getcwd()) + '/../data_load'\n",
    "sys.path.insert(0, path)\n",
    "\n",
    "from scoring import Scoring\n",
    "from ufo_data import UFOData\n",
    "\n",
    "\n",
    "names=['datetime', 'city','state', 'shape', 'duration(seconds)', 'comments','date posted', 'longitude', 'latitude']\n",
    "loader = UFOData(names, 'us')\n",
    "data = loader.encoded()\n",
    "\n",
    "#calculate credibility scores on data\n",
    "s = Scoring(data)\n",
    "scored_data = s.calc_scores()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names=['state', 'duration(seconds)', 'longitude', 'latitude', 'posted_ts', 'dbscan_cluster','credibility']    \n",
    "X = scored_data[names]   \n",
    "Y = scored_data['shape']\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_data(X, Y)\n",
    "\n",
    "print('SVM')\n",
    "svm(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print('Random Forest')\n",
    "RandomForest(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "0.208397534669\n",
      "Random Forest\n",
      "0.130277349769\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-c3ce0334c02d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Random Forest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mRandomForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-5f8399b93fb6>\u001b[0m in \u001b[0;36mRandomForest\u001b[0;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2475\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2476\u001b[0m             return self._engine.get_value(s, k,\n\u001b[0;32m-> 2477\u001b[0;31m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[1;32m   2478\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2479\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'integer'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'boolean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas/_libs/index.c:4404)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas/_libs/index.c:4087)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas/_libs/index.c:5126)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas/_libs/hashtable.c:14031)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas/_libs/hashtable.c:13975)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "names=['state', 'duration(seconds)', 'longitude', 'latitude']\n",
    "\n",
    "X = data[names]   \n",
    "Y = data['shape']\n",
    "\n",
    "X_train, X_test, y_train, y_test = prepare_data(X, Y)\n",
    "print('SVM')\n",
    "svm(X_train, y_train, X_test, y_test)\n",
    "\n",
    "print('Random Forest')\n",
    "RandomForest(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
