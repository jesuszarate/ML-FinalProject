{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as  np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, time\n",
    "\n",
    "def dateToInt(x):    \n",
    "    _date = x.split('/')\n",
    "    \n",
    "    year, time = _date[2].split()\n",
    "    hour, minute = time.split(':')\n",
    "\n",
    "    if int(hour) > 23:\n",
    "        hour = 23\n",
    "    if int(hour) < 0:\n",
    "        hour = 0\n",
    "        \n",
    "    t = datetime.datetime(int(year), int(_date[0]), int(_date[1]), int(hour), int(minute), 0, 0).timestamp()\n",
    "    return t\n",
    "\n",
    "def getLabelMap(data):\n",
    "    # Map shape to an integer\n",
    "    labels = data['shape']\n",
    "    labels = labels.unique()\n",
    "    nums = [i for i in range(len(labels))]\n",
    "    return dict(zip(labels, nums))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def vectorize(text):    \n",
    "    # create the transform\n",
    "    vectorizer = CountVectorizer()\n",
    "\n",
    "    # tokenize and build vocab\n",
    "    vectorizer.fit(text)\n",
    "\n",
    "    # encode document\n",
    "    vector = vectorizer.transform(text)\n",
    "\n",
    "    return vector.toarray()\n",
    "\n",
    "def vectorize_dm(text):\n",
    "    n_features = 5000\n",
    "    n_top_words = 20\n",
    "\n",
    "    count_vectorizor = CountVectorizer(\n",
    "            max_df=0.95, \n",
    "            min_df=2,\n",
    "            max_features=n_features,\n",
    "            stop_words='english'\n",
    "    )\n",
    "    count = count_vectorizor.fit_transform(text)\n",
    "#     count_feature_names = count_vectorizor.get_feature_names()\n",
    "#     print(count_feature_names)\n",
    "    return count.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# list of text documents\n",
    "text = [\"The quick brown fox jumped over the lazy dog.\",\n",
    "        \"The dog.\",\n",
    "        \"The fox\"]\n",
    "# create the transform\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# tokenize and build vocab\n",
    "vector = vectorizer.fit_transform(text)\n",
    "\n",
    "# # summarize\n",
    "# print(vectorizer.vocabulary_)\n",
    "# print(vectorizer.idf_)\n",
    "\n",
    "# # encode document\n",
    "# vector = vectorizer.transform(text)\n",
    "\n",
    "# summarize encoded vector\n",
    "# print(vector.shape)\n",
    "print(vector.toarray())\n",
    "print('\\n')\n",
    "adf = pd.DataFrame(vector.todense())\n",
    "adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64896, 5001)\n",
      "(64896, 12)\n"
     ]
    }
   ],
   "source": [
    "names=['datetime', 'city', 'state', 'country',\n",
    "                              'shape', 'duration(seconds)', 'duration(hours/min)', 'comments',\n",
    "                              'date posted', 'longitude', 'latitude']\n",
    "data = pd.read_csv('ufo-scrubbed-geocoded-time-standardized.csv',\n",
    "                   names=names,\n",
    "                   dtype=object,\n",
    "                   error_bad_lines=False, warn_bad_lines=False)\n",
    "\n",
    "data = data[data['country'] == 'us']\n",
    "\n",
    "# Columns currently not using\n",
    "# names.remove('shape')\n",
    "names.remove('date posted')\n",
    "names.remove('duration(hours/min)')\n",
    "names.remove('country')\n",
    "names.remove('state')\n",
    "names.remove('city')\n",
    "\n",
    "# Make date into ints\n",
    "data['datetime'] = data.datetime.apply(lambda x: dateToInt(x))\n",
    "\n",
    "# Filter rows that have strings in the duration column\n",
    "data = data[data['duration(seconds)'].apply(lambda x : str.isdigit(x))]\n",
    "\n",
    "# Add keys to be able to merge\n",
    "data['key'] = [i for i in range(data.shape[0])]\n",
    "names.append('key')\n",
    "\n",
    "# Get rid of unicode characters\n",
    "text = data[\"comments\"].apply(lambda x: ''.join([\" \" if ord(i) < 32 or ord(i) > 126 else i for i in str(x)]))\n",
    "\n",
    "# Create dataframe out of the comment vector\n",
    "commentDf = pd.DataFrame(vectorize_dm(text))\n",
    "commentDf['key'] = [i for i in range(commentDf.shape[0])]\n",
    "print(commentDf.shape)\n",
    "print(data.shape)\n",
    "\n",
    "# Merge comment dataframe and original dataframe\n",
    "# data.merge(commentDf, on='key', how='left')\n",
    "\n",
    "# data.shape[0]\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the comment vectors with data\n",
    "#### Takes a  long time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration(seconds)</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>key</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>...</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-638224200.0</td>\n",
       "      <td>cylinder</td>\n",
       "      <td>2700</td>\n",
       "      <td>29.8830556</td>\n",
       "      <td>-97.9411111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-417297600.0</td>\n",
       "      <td>circle</td>\n",
       "      <td>20</td>\n",
       "      <td>28.9783333</td>\n",
       "      <td>-96.6458333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-291070800.0</td>\n",
       "      <td>light</td>\n",
       "      <td>900</td>\n",
       "      <td>21.4180556</td>\n",
       "      <td>-157.8036111</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-259538400.0</td>\n",
       "      <td>sphere</td>\n",
       "      <td>300</td>\n",
       "      <td>36.5950000</td>\n",
       "      <td>-82.1888889</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-133294500.0</td>\n",
       "      <td>disk</td>\n",
       "      <td>1200</td>\n",
       "      <td>41.1175000</td>\n",
       "      <td>-73.4083333</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5006 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      datetime     shape duration(seconds)   longitude      latitude  key  0  \\\n",
       "0 -638224200.0  cylinder              2700  29.8830556   -97.9411111    0  0   \n",
       "1 -417297600.0    circle                20  28.9783333   -96.6458333    1  0   \n",
       "2 -291070800.0     light               900  21.4180556  -157.8036111    2  0   \n",
       "3 -259538400.0    sphere               300  36.5950000   -82.1888889    3  0   \n",
       "4 -133294500.0      disk              1200  41.1175000   -73.4083333    4  0   \n",
       "\n",
       "   1  2  3  ...   4990  4991  4992  4993  4994  4995  4996  4997  4998  4999  \n",
       "0  0  0  0  ...      0     0     0     0     0     0     0     0     0     0  \n",
       "1  0  0  0  ...      0     0     0     0     0     0     0     0     0     0  \n",
       "2  0  0  0  ...      0     0     0     0     0     0     0     0     0     0  \n",
       "3  0  0  0  ...      0     0     0     0     0     0     0     0     0     0  \n",
       "4  0  0  0  ...      0     0     0     0     0     0     0     0     0     0  \n",
       "\n",
       "[5 rows x 5006 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since we already vectorized the comments we can get rid of them now\n",
    "if 'comments' in names:\n",
    "    names.remove('comments')\n",
    "    \n",
    "dt = data[names].merge(commentDf, on='key', how='left')\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = getLabelMap(dt)\n",
    "\n",
    "Y = np.array([label_dict[i] for i in dt['shape']])\n",
    "\n",
    "x_cols = list(dt)\n",
    "\n",
    "if 'shape' in x_cols:\n",
    "    x_cols.remove('shape')\n",
    "\n",
    "X = dt[x_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Principle Component Anaysis (PCA) to only extract the 100 most relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=100)\n",
    "XX = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    Y,\n",
    "    test_size=0.2, \n",
    "    random_state=42)\n",
    "# print(X_train.shape, y_train.shape)\n",
    "# print(X_test.shape, y_test.shape)\n",
    "# print(X.shape)\n",
    "# print(X.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=25, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# rf = RandomForestClassifier(n_estimators=25)\n",
    "rf = RandomForestClassifier(n_estimators=25, max_features='auto', max_depth=None)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5961\n"
     ]
    }
   ],
   "source": [
    "# pred = rf.predict(X_test)\n",
    "y_pred_probs = rf.predict_proba(X_test)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "\n",
    "s = y_test\n",
    "count = 0\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] == s[i]:\n",
    "        count += 1\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy and F Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45924499229583976"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scores = f1_score(y_test, y_guess, average=None)\n",
    "scores = f1_score(y_test, y_pred, average='weighted', labels=np.unique(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.437853538339\n",
      "0.437853538339\n"
     ]
    }
   ],
   "source": [
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
